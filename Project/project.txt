{
    from pyspark.sql import SparkSession
    from pyspark.sql.functions import when, col, mean
    from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler
    from pyspark.ml.classification import LogisticRegression
    from pyspark.ml.evaluation import MulticlassClassificationEvaluator
    from pyspark.ml import Pipeline
    import matplotlib.pyplot as plt

    @REM 1. Initilizing Spark Session

    spark = SparkSession.builder.appName("StudentResultPrediction").getOrCreate()

    @REM 2. Load DataSet

    df = spark.read.csv("C:/Users/Navneet singh/Downloads/StudentsPerformance.csv",header=True,inferSchema=True)

    @REM Display Schema

    df.printSchema()

    @REM removing the null and missing Values

    @REM df = df.na.drop()

    @REM # List of numeric columns where you want to fill missing values

    numeric_cols = ["math score", "reading score", "writing score"]

    @REM # Compute mean for each numeric column

  
    mean_values = df.select([mean(c).alias(c) for c in numeric_cols]).collect()[0]

    @REM  # Replace null values with the corresponding mean value
    @REM # Fill missing values

    df = df.na.fill({c: mean_values[c] for c in numeric_cols})
    

    @REM  3. Create target variable (Pass/Fail)

    df = df.withColumn("average_score",(col("math score") + col("reading score") + col("writing score"))/3)

    df = df.withColumn("passed",when(col("average_score") >= 50,1).otherwise(0))

    @REM 4. Encode categorical features

    categorical_cols = ["gender","race/ethnicity","parental level of education","lunch","test preparation course"]

    indexers = [StringIndexer(inputCol = c, outputCol=c + "_indexed") for c in categorical_cols]

    encoders = [OneHotEncoder(inputCol=c + "_indexed",outputCol=c + "_encoded") for c in categorical_cols]

    feature_cols = [c + "_encoded" for c in categorical_cols] + ["math score","reading score","writing score"]


    @REM assembler = VectorAssembler(inputCols=["math score", "reading score", "writing score"],outputCol="features")

    assembler = VectorAssembler(inputCols=feature_cols, outputCol="features")

    @REM 5. Building logistic regression pipline

    lr = LogisticRegression(featuresCol="features", labelCol="passed")
    
    pipeline = Pipeline(stages=indexers + encoders + [assembler, lr])


    @REM 6. Train and Test split

    train_df, test_df = df.randomSplit([0.7,0.3])

    @REM Train model

    model = pipeline.fit(train_df)

    @REM 7. predictions

    predictions = model.transform(test_df)

    @REM 8. Evaluate model

    evaluator_acc = MulticlassClassificationEvaluator(labelCol="passed", predictionCol="prediction", metricName="accuracy")

    evaluator_f1 = MulticlassClassificationEvaluator(labelCol="passed", predictionCol="prediction", metricName="f1")

    accuracy = evaluator_acc.evaluate(predictions)
    
    f1 = evaluator_f1.evaluate(predictions)

    print(f"Accuracy: {accuracy:.4f}")
    print(f"F1-Score: {f1:.4f}")


    @REM  9. Visualization

    pdf = predictions.select("passed", "prediction").toPandas()
    counts = pdf.value_counts(["passed", "prediction"]).reset_index(name="count")


    plt.bar(counts["passed"].astype(str) + "-" + counts["prediction"].astype(str), counts["count"])
    plt.xlabel("Actual-Predicted (0=Fail, 1=Pass)")
    plt.ylabel("Count")
    plt.title("Actual vs Predicted Results")
    plt.show()

    predictions.select("gender", "race/ethnicity", "parental level of education","lunch", "test preparation course", "math score", "reading score", "writing score", "passed", "prediction").toPandas().to_csv("C:/Users/Navneet singh/Downloads/student_predictions.csv", index=False)


}